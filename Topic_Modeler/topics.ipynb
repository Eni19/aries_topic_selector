{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02ce902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import pickle\n",
    "import gsdmm\n",
    "from gsdmm import MovieGroupProcess\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9194aae",
   "metadata": {},
   "source": [
    "Ler o CSV criado previamente e converter tokens em listas de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da489b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\Pessoal\\AppData\\Local\\Temp\\ipykernel_13592\\783247071.py:4: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  tweets_df['tokens'] = tweets_df.tokens.apply(lambda x:  re.split('\\s', x))\n"
     ]
    }
   ],
   "source": [
    "caminho_arquivo = r'C:\\Users\\Pessoal\\Documents\\Unifesp\\Aries\\aries_topic_selector\\Noise_remover\\tweets_processados.csv'\n",
    "tweets_df = pd.read_csv(caminho_arquivo)\n",
    "tweets_df.dropna(axis='columns', inplace=True)\n",
    "tweets_df['tokens'] = tweets_df.tokens.apply(lambda x:  re.split('\\s', x))\n",
    "docs = tweets_df['tokens'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1da713",
   "metadata": {},
   "source": [
    "# Treinamento do Modelo usando o GSDMM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d97a321",
   "metadata": {},
   "source": [
    "Agora, aplicaremos o GSDMM (Gibbs Sampling Dirichlet Mixture Model) , com os seguintes parâmetros:\n",
    "- K — É o número máximo de topicos a serem encontrados\n",
    "- Alpha α - Determina o quão fácil mesas pequenas são removidas\n",
    "- Beta β - Controla se uma mesa é escolhida por popularidade ou similaridade. Quanto menor, mais popular\n",
    "- N_iters - Número de vezes em que um Subject é realocado numa nova mesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c643aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\A'\n",
      "C:\\Users\\Pessoal\\AppData\\Local\\Temp\\ipykernel_13592\\3350084293.py:7: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  with open(\"C:\\\\Users\\\\Pessoal\\\\Documents\\\\Unifesp\\Aries\\\\aries_topic_selector\\\\modelos_treinados\\\\10clusters.model\", 'wb') as f:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In stage 0: transferred 3416 clusters with 10 clusters populated\n",
      "In stage 1: transferred 2094 clusters with 10 clusters populated\n",
      "In stage 2: transferred 1586 clusters with 10 clusters populated\n",
      "In stage 3: transferred 1268 clusters with 10 clusters populated\n",
      "In stage 4: transferred 1029 clusters with 10 clusters populated\n",
      "In stage 5: transferred 955 clusters with 10 clusters populated\n",
      "In stage 6: transferred 896 clusters with 10 clusters populated\n",
      "In stage 7: transferred 838 clusters with 10 clusters populated\n",
      "In stage 8: transferred 811 clusters with 10 clusters populated\n",
      "In stage 9: transferred 800 clusters with 10 clusters populated\n",
      "In stage 10: transferred 756 clusters with 10 clusters populated\n",
      "In stage 11: transferred 704 clusters with 10 clusters populated\n",
      "In stage 12: transferred 703 clusters with 10 clusters populated\n",
      "In stage 13: transferred 667 clusters with 10 clusters populated\n",
      "In stage 14: transferred 682 clusters with 10 clusters populated\n",
      "In stage 15: transferred 662 clusters with 10 clusters populated\n",
      "In stage 16: transferred 698 clusters with 10 clusters populated\n",
      "In stage 17: transferred 645 clusters with 10 clusters populated\n",
      "In stage 18: transferred 626 clusters with 10 clusters populated\n",
      "In stage 19: transferred 656 clusters with 10 clusters populated\n",
      "In stage 20: transferred 605 clusters with 10 clusters populated\n",
      "In stage 21: transferred 603 clusters with 10 clusters populated\n",
      "In stage 22: transferred 598 clusters with 10 clusters populated\n",
      "In stage 23: transferred 632 clusters with 10 clusters populated\n",
      "In stage 24: transferred 619 clusters with 10 clusters populated\n",
      "In stage 25: transferred 633 clusters with 10 clusters populated\n",
      "In stage 26: transferred 602 clusters with 10 clusters populated\n",
      "In stage 27: transferred 593 clusters with 10 clusters populated\n",
      "In stage 28: transferred 588 clusters with 10 clusters populated\n",
      "In stage 29: transferred 624 clusters with 10 clusters populated\n"
     ]
    }
   ],
   "source": [
    "mgp = MovieGroupProcess(K=10, alpha=0.1, beta=0.1, n_iters=30)\n",
    "vocab = set(x for doc in docs for x in doc)\n",
    "n_terms = len(vocab)\n",
    "y = mgp.fit(docs, n_terms)\n",
    "\n",
    "\n",
    "with open(\"C:\\\\Users\\\\Pessoal\\\\Documents\\\\Unifesp\\Aries\\\\aries_topic_selector\\\\modelos_treinados\\\\10clusters.model\", 'wb') as f:\n",
    "    pickle.dump(mgp, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ec9e2b",
   "metadata": {},
   "source": [
    "# Explorando os Tópicos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca277124",
   "metadata": {},
   "source": [
    "Definiremos algumas funções para ajudar a explorar os tópicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "426b42e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_words(cluster_word_distribution, top_cluster, values):\n",
    "    '''prints the top words in each cluster'''\n",
    "    for cluster in top_cluster:\n",
    "        sort_dicts =sorted(mgp.cluster_word_distribution[cluster].items(), key=lambda k: k[1], reverse=True)[:values]\n",
    "        print('Cluster %s : %s'%(cluster,sort_dicts))\n",
    "        print(' — — — — — — — — —')\n",
    "\n",
    "def cluster_importance(mgp):\n",
    "    '''returns a word-topic matrix[phi] where each value represents\n",
    "    the word importance for that particular cluster;\n",
    "    phi[i][w] would be the importance of word w in topic i.\n",
    "    '''\n",
    "    n_z_w = mgp.cluster_word_distribution\n",
    "    beta, V, K = mgp.beta, mgp.vocab_size, mgp.K\n",
    "    phi = [{} for i in range(K)]\n",
    "    for z in range(K):\n",
    "        for w in n_z_w[z]:\n",
    "            phi[z][w] = (n_z_w[z][w]+beta)/(sum(n_z_w[z].values())+V*beta)\n",
    "    return phi\n",
    "\n",
    "def topic_allocation(df, docs, mgp, topic_dict):\n",
    "    '''allocates all topics to each document in original dataframe,\n",
    "    adding two columns for cluster number and cluster description'''\n",
    "    topic_allocations = []\n",
    "    for doc in tqdm(docs):\n",
    "        topic_label, score = mgp.choose_best_label(doc)\n",
    "        topic_allocations.append(topic_label)\n",
    "\n",
    "    df['cluster'] = topic_allocations\n",
    "\n",
    "    df['topic_name'] = df.cluster.apply(lambda x: get_topic_name(x, topic_dict))\n",
    "    print('Complete. Number of documents with topic allocated: {}'.format(len(df)))\n",
    "\n",
    "def get_topic_name(doc, topic_dict):\n",
    "    '''returns the topic name string value from a dictionary of topics'''\n",
    "    topic_desc = topic_dict[doc]\n",
    "    return topic_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec576b7b",
   "metadata": {},
   "source": [
    "Insight estatístico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26154742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents per topic : [ 188   48  134  144 1161  170  920 1093   58  352]\n",
      "********************\n",
      "Most important clusters (by number of docs inside): [4 7 6 9 0 5 3 2 8 1]\n",
      "********************\n",
      "Cluster 0 : [('infecção', 178), ('urinário', 135), ('urinario', 26), ('dor', 25), ('semana', 24)]\n",
      " — — — — — — — — —\n",
      "Cluster 1 : [('infecção', 42), ('atendimento', 34), ('pré', 32), ('hospitalar', 31), ('urinário', 25)]\n",
      " — — — — — — — — —\n",
      "Cluster 2 : [('infecção', 135), ('urinário', 101), ('mulher', 30), ('urinár', 29), ('ter', 29)]\n",
      " — — — — — — — — —\n",
      "Cluster 3 : [('infecção', 139), ('urinário', 110), ('gato', 32), ('ano', 21), ('urinár', 20)]\n",
      " — — — — — — — — —\n",
      "Cluster 4 : [('infecção', 1104), ('urinário', 852), ('água', 259), ('xixi', 225), ('urinario', 219)]\n",
      " — — — — — — — — —\n",
      "Cluster 5 : [('infecção', 172), ('urinário', 162), ('gil', 119), ('preto', 90), ('internar', 87)]\n",
      " — — — — — — — — —\n",
      "Cluster 6 : [('infecção', 982), ('urinário', 747), ('exame', 237), ('médico', 211), ('ter', 157)]\n",
      " — — — — — — — — —\n",
      "Cluster 7 : [('infecção', 1069), ('urinário', 909), ('dor', 321), ('ir', 131), ('achar', 130)]\n",
      " — — — — — — — — —\n",
      "Cluster 8 : [('infecção', 53), ('urinário', 40), ('urinario', 15), ('etc', 7), ('ansiedade', 6)]\n",
      " — — — — — — — — —\n",
      "Cluster 9 : [('infecção', 380), ('urinário', 294), ('xixi', 108), ('evitar', 62), ('mulher', 53)]\n",
      " — — — — — — — — —\n"
     ]
    }
   ],
   "source": [
    "doc_count = np.array(mgp.cluster_doc_count)\n",
    "print('Number of documents per topic :', doc_count)\n",
    "print('*'*20)\n",
    "# topics sorted by the number of documents they are allocated to\n",
    "top_index = doc_count.argsort()[-10:][::-1]\n",
    "print('Most important clusters (by number of docs inside):',top_index)\n",
    "print('*'*20)\n",
    "# show the top 5 words in term frequency for each cluster \n",
    "topic_indices = np.arange(start=0, stop=len(doc_count), step=1)\n",
    "top_words(mgp.cluster_word_distribution, topic_indices, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dde7550",
   "metadata": {},
   "source": [
    "Se quisermos ver a importância de algumas palavras , usando a função cluster_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becab96c",
   "metadata": {},
   "source": [
    "Agora, decidimos o que é  cada tópico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc671715",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4268/4268 [00:01<00:00, 3300.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete. Number of documents with topic allocated: 4268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "topic_dict = {}\n",
    "topic_names = ['Cluster 0,',\n",
    "                'Cluster 1,',\n",
    "                'Cluster 2,',\n",
    "                'Cluster 3,',\n",
    "                'Cluster 4,',\n",
    "                'Cluster 5,',\n",
    "                'Cluster 6,',\n",
    "                'Cluster 7,',\n",
    "                'Cluster 8,',\n",
    "                'Cluster 9,']\n",
    "\n",
    "for i, topic_num in enumerate(topic_indices):\n",
    " topic_dict[topic_num]=topic_names[i]\n",
    "\n",
    "\n",
    "\n",
    "topic_allocation(tweets_df, docs, mgp, topic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f1b759",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.to_excel('sttm_10topics_results.xlsx', index = False,  header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
